{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN7p0XBjzXI/QfB8OVQcIqB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanCecil01/ContextSearch/blob/main/context_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omBNdlJn-kTL"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "SM0gy5gY-wUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "iZHZpceK_wzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from PyPDF2 import PdfReader\n",
        "import json"
      ],
      "metadata": {
        "id": "EslVIYLO_D2q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "-d0GBNgf_mPN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(path):\n",
        "    # creating a pdf reader object\n",
        "    reader = PdfReader(path)\n",
        "\n",
        "    # printing number of pages in pdf file\n",
        "    print(len(reader.pages))\n",
        "\n",
        "    # getting a specific page from the pdf file\n",
        "    text_array = []\n",
        "\n",
        "\n",
        "    for i in range(20, len(reader.pages)-20):\n",
        "    # extracting text from page\n",
        "        page = reader.pages[i]\n",
        "        text = page.extract_text()\n",
        "        text_array.append(text)\n",
        "\n",
        "    return text_array"
      ],
      "metadata": {
        "id": "W-6RcLCm-1W2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each page using spaCy\n",
        "\n",
        "def sentence_extraction(filename):\n",
        "  text_array =  extract_text_from_pdf(filename)\n",
        "  processed_pages = []\n",
        "  page_no = 0\n",
        "  for page in text_array:\n",
        "      doc = nlp(page)\n",
        "      processed_pages.append([doc, page_no])\n",
        "      page_no+=1\n",
        "\n",
        "\n",
        "  sentences = []\n",
        "  for doc, page_no in processed_pages:\n",
        "      for sentence in doc.sents:\n",
        "          sentences.append([sentence, page_no])\n",
        "  return sentences\n"
      ],
      "metadata": {
        "id": "5GGhI5oVBLJU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_json_file(context_sents, filename):\n",
        "  sentences = sentence_extraction(filename)\n",
        "  context_dict = {}\n",
        "  for input_sent in context_sents:\n",
        "    context_dict[input_sent] = []\n",
        "\n",
        "  for input_sent in context_sents:\n",
        "    # Process the input sentence\n",
        "    input_doc = nlp(input_sent)\n",
        "\n",
        "    # Calculate similarity with each sentence\n",
        "    similarity_scores = []\n",
        "    for sentence, page_no in sentences:\n",
        "        similarity_score = input_doc.similarity(sentence)\n",
        "        similarity_scores.append((sentence, similarity_score, page_no))\n",
        "\n",
        "    # Sort similarity scores in descending order\n",
        "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    i = 0\n",
        "    # Print the most similar sentences\n",
        "    for sentence, similarity_score, page_no in similarity_scores:\n",
        "        temp_dict = {}\n",
        "        temp_dict['file'] = filename\n",
        "        temp_dict['page_no'] = page_no\n",
        "        temp_dict['sentence'] = sentence.text\n",
        "        temp_dict['similarity_score'] = similarity_score\n",
        "        context_dict[input_sent].append(temp_dict)\n",
        "        if i==10:\n",
        "          break\n",
        "        i+=1\n",
        "\n",
        "    print(context_dict)\n",
        "\n",
        "    json_string = json.dumps(context_dict, indent = 2)\n",
        "    with open(\"context_search_results.json\", \"w\") as f:\n",
        "      f.write(json_string)\n",
        "\n"
      ],
      "metadata": {
        "id": "hk9ve2RAZIq-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_json_file([\"neural networks are the best for image recognition\", \"RNN is difficult\", \"Learning Word embeddings\", \"Transformers are just complex networks\"], '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCXeiVf6bCSN",
        "outputId": "1bc6d400-341a-486d-f488-ae48b0d031f9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-ebdc217cd53d>:14: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  similarity_score = input_doc.similarity(sentence)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neural networks are the best for image recognition': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 199, 'sentence': 'Convolutional neural networks are used for image\\nrecognition and prediction.', 'similarity_score': 0.9343882001078312}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 39, 'sentence': '1.6.5 Convolutional Neural Networks\\nConvolutional neural networks are biologically inspired networks that are used in computer\\nvision for image classiﬁcation and object detection.', 'similarity_score': 0.9264531609446556}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 366, 'sentence': 'The two most popular data sets for testing convolutional neural networks are MNIST\\nandImageNet .', 'similarity_score': 0.9095713538369533}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 52, 'sentence': 'Neural networks are also parameterized models that are learned with continuous optimiza-\\ntion methods.', 'similarity_score': 0.9064293273065994}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 426, 'sentence': 'The hidden states within the\\nneural network can be viewed in a similar way to CPU registers that are used for transitory\\ncomputation, whereas the external memory is used for persistent computation.', 'similarity_score': 0.9016970820213827}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'Deformable part models are convolutional\\nneural networks.', 'similarity_score': 0.8983858231825262}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 281, 'sentence': 'Bidirectional recurrent neural networks are appropriate for applications in which the pre-\\ndictions are not causal based on a historical window.', 'similarity_score': 0.8972948367714159}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 211, 'sentence': 'However, the results of generative\\nadversarial networks are often more realistic because the decoders are explicitly trained to\\ncreate good counterfeits.', 'similarity_score': 0.8968398967818455}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 212, 'sentence': 'Several regularization\\nmethods have also been proposed that are speciﬁcally designed for neural architectures.\\n', 'similarity_score': 0.8968308355195864}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 187, 'sentence': 'One possibility is to predict the test instance using all the neural networks\\nthat were sampled, and then use the geometric mean of the probabilities that are predicted\\nby the diﬀerent networks.', 'similarity_score': 0.8968118360821143}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 64, 'sentence': 'The key point is that with\\ngreater availability of data one can incorporate additional nodes and depth to increase the\\nmodel’s capacity, explaining the superior behavior of neural networks with larger data sets\\n(cf. Figure 2.1).\\n2.3 Neural Architectures for Multiclass Models\\nAll the models discussed so far in this chapter are designed for binary classiﬁcation.', 'similarity_score': 0.8963874265833632}], 'RNN is difficult': [], 'Learning Word embeddings': [], 'Transformers are just complex networks': []}\n",
            "{'neural networks are the best for image recognition': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 199, 'sentence': 'Convolutional neural networks are used for image\\nrecognition and prediction.', 'similarity_score': 0.9343882001078312}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 39, 'sentence': '1.6.5 Convolutional Neural Networks\\nConvolutional neural networks are biologically inspired networks that are used in computer\\nvision for image classiﬁcation and object detection.', 'similarity_score': 0.9264531609446556}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 366, 'sentence': 'The two most popular data sets for testing convolutional neural networks are MNIST\\nandImageNet .', 'similarity_score': 0.9095713538369533}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 52, 'sentence': 'Neural networks are also parameterized models that are learned with continuous optimiza-\\ntion methods.', 'similarity_score': 0.9064293273065994}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 426, 'sentence': 'The hidden states within the\\nneural network can be viewed in a similar way to CPU registers that are used for transitory\\ncomputation, whereas the external memory is used for persistent computation.', 'similarity_score': 0.9016970820213827}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'Deformable part models are convolutional\\nneural networks.', 'similarity_score': 0.8983858231825262}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 281, 'sentence': 'Bidirectional recurrent neural networks are appropriate for applications in which the pre-\\ndictions are not causal based on a historical window.', 'similarity_score': 0.8972948367714159}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 211, 'sentence': 'However, the results of generative\\nadversarial networks are often more realistic because the decoders are explicitly trained to\\ncreate good counterfeits.', 'similarity_score': 0.8968398967818455}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 212, 'sentence': 'Several regularization\\nmethods have also been proposed that are speciﬁcally designed for neural architectures.\\n', 'similarity_score': 0.8968308355195864}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 187, 'sentence': 'One possibility is to predict the test instance using all the neural networks\\nthat were sampled, and then use the geometric mean of the probabilities that are predicted\\nby the diﬀerent networks.', 'similarity_score': 0.8968118360821143}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 64, 'sentence': 'The key point is that with\\ngreater availability of data one can incorporate additional nodes and depth to increase the\\nmodel’s capacity, explaining the superior behavior of neural networks with larger data sets\\n(cf. Figure 2.1).\\n2.3 Neural Architectures for Multiclass Models\\nAll the models discussed so far in this chapter are designed for binary classiﬁcation.', 'similarity_score': 0.8963874265833632}], 'RNN is difficult': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 94, 'sentence': 'This is where eﬃciency is achieved.', 'similarity_score': 0.9110095728722907}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 435, 'sentence': 'This is the', 'similarity_score': 0.8362565495595152}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 170, 'sentence': 'Dropout is\\nanother ensemble technique that is designed for neural networks.', 'similarity_score': 0.8354687407592949}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 114, 'sentence': 'This is why backpropagation is sometimes understood as error propagation.\\n', 'similarity_score': 0.826495813556712}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 182, 'sentence': 'This is the reason that L2-\\nregularization is almost always preferred over L1-regularization is most implementations.\\n', 'similarity_score': 0.8220441939840075}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 186, 'sentence': 'It is\\nnoteworthythatthisapproachmightseemsuperﬁciallysimilarto DropoutandDropConnect ,\\nalthough it is quite diﬀerent.', 'similarity_score': 0.8147961157897934}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 222, 'sentence': 'The main problem with this approach is that it is extremely ineﬃcient.', 'similarity_score': 0.812601525284322}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 197, 'sentence': 'This process is repeated until the complex optimization problem is solved.', 'similarity_score': 0.8104838955955365}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 168, 'sentence': 'It is clear that the linear model is\\nstable,althoughitisunabletoexactlymodelthecurvednatureofthetruedatadistribution.\\n', 'similarity_score': 0.8088913355085388}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 14, 'sentence': 'This is because |y/2−0.5+ˆy|indicates the probability that the\\nprediction is correct.', 'similarity_score': 0.8007653719878096}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 51, 'sentence': 'Regulariza-\\ntion is not used.\\n', 'similarity_score': 0.7976935998398553}], 'Learning Word embeddings': [], 'Transformers are just complex networks': []}\n",
            "{'neural networks are the best for image recognition': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 199, 'sentence': 'Convolutional neural networks are used for image\\nrecognition and prediction.', 'similarity_score': 0.9343882001078312}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 39, 'sentence': '1.6.5 Convolutional Neural Networks\\nConvolutional neural networks are biologically inspired networks that are used in computer\\nvision for image classiﬁcation and object detection.', 'similarity_score': 0.9264531609446556}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 366, 'sentence': 'The two most popular data sets for testing convolutional neural networks are MNIST\\nandImageNet .', 'similarity_score': 0.9095713538369533}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 52, 'sentence': 'Neural networks are also parameterized models that are learned with continuous optimiza-\\ntion methods.', 'similarity_score': 0.9064293273065994}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 426, 'sentence': 'The hidden states within the\\nneural network can be viewed in a similar way to CPU registers that are used for transitory\\ncomputation, whereas the external memory is used for persistent computation.', 'similarity_score': 0.9016970820213827}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'Deformable part models are convolutional\\nneural networks.', 'similarity_score': 0.8983858231825262}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 281, 'sentence': 'Bidirectional recurrent neural networks are appropriate for applications in which the pre-\\ndictions are not causal based on a historical window.', 'similarity_score': 0.8972948367714159}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 211, 'sentence': 'However, the results of generative\\nadversarial networks are often more realistic because the decoders are explicitly trained to\\ncreate good counterfeits.', 'similarity_score': 0.8968398967818455}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 212, 'sentence': 'Several regularization\\nmethods have also been proposed that are speciﬁcally designed for neural architectures.\\n', 'similarity_score': 0.8968308355195864}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 187, 'sentence': 'One possibility is to predict the test instance using all the neural networks\\nthat were sampled, and then use the geometric mean of the probabilities that are predicted\\nby the diﬀerent networks.', 'similarity_score': 0.8968118360821143}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 64, 'sentence': 'The key point is that with\\ngreater availability of data one can incorporate additional nodes and depth to increase the\\nmodel’s capacity, explaining the superior behavior of neural networks with larger data sets\\n(cf. Figure 2.1).\\n2.3 Neural Architectures for Multiclass Models\\nAll the models discussed so far in this chapter are designed for binary classiﬁcation.', 'similarity_score': 0.8963874265833632}], 'RNN is difficult': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 94, 'sentence': 'This is where eﬃciency is achieved.', 'similarity_score': 0.9110095728722907}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 435, 'sentence': 'This is the', 'similarity_score': 0.8362565495595152}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 170, 'sentence': 'Dropout is\\nanother ensemble technique that is designed for neural networks.', 'similarity_score': 0.8354687407592949}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 114, 'sentence': 'This is why backpropagation is sometimes understood as error propagation.\\n', 'similarity_score': 0.826495813556712}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 182, 'sentence': 'This is the reason that L2-\\nregularization is almost always preferred over L1-regularization is most implementations.\\n', 'similarity_score': 0.8220441939840075}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 186, 'sentence': 'It is\\nnoteworthythatthisapproachmightseemsuperﬁciallysimilarto DropoutandDropConnect ,\\nalthough it is quite diﬀerent.', 'similarity_score': 0.8147961157897934}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 222, 'sentence': 'The main problem with this approach is that it is extremely ineﬃcient.', 'similarity_score': 0.812601525284322}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 197, 'sentence': 'This process is repeated until the complex optimization problem is solved.', 'similarity_score': 0.8104838955955365}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 168, 'sentence': 'It is clear that the linear model is\\nstable,althoughitisunabletoexactlymodelthecurvednatureofthetruedatadistribution.\\n', 'similarity_score': 0.8088913355085388}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 14, 'sentence': 'This is because |y/2−0.5+ˆy|indicates the probability that the\\nprediction is correct.', 'similarity_score': 0.8007653719878096}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 51, 'sentence': 'Regulariza-\\ntion is not used.\\n', 'similarity_score': 0.7976935998398553}], 'Learning Word embeddings': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 43, 'sentence': '1.7.1 Reinforcement Learning\\n', 'similarity_score': 0.7416167008887713}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'Deep Reinforcement Learning with Double Q-\\nLearning.', 'similarity_score': 0.6586812822746783}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 390, 'sentence': '9.5.3 Combining Supervised Learning with Policy Gradients\\nSupervisedlearningisusefulforinitializingtheweightsofthepolicynetworkbeforeapplying\\nreinforcement learning.', 'similarity_score': 0.656674241395668}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'node2vec: Scalable feature learning for networks.', 'similarity_score': 0.6538957611568217}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 52, 'sentence': 'Chapter 2\\nMachine Learning with Shallow Neural\\nNetworks\\n“Simplicity is the ultimate sophistication.”—Leonardo', 'similarity_score': 0.6504808769623618}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 86, 'sentence': 'WORD2VEC: AN APPLICATION OF SIMPLE NEURAL ARCHITECTURES 87\\n2.6 Word2vec: An Application of Simple Neural Archi-\\ntectures\\nNeural network methods have been used to learn word embeddings of text data.', 'similarity_score': 0.6438643682140834}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 197, 'sentence': '2.Curriculum learning:', 'similarity_score': 0.6415818162349093}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 396, 'sentence': '•Reinforcement learning:', 'similarity_score': 0.6415818162349093}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 461, 'sentence': 'NIPS 2016 tutorial: Generative adversarial networks.', 'similarity_score': 0.6401220310180029}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 456, 'sentence': 'Radial Basis Functions: Theory and implementations.', 'similarity_score': 0.6398878282053853}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 312, 'sentence': 'Large Scale Visual Recognition Challenge', 'similarity_score': 0.638335210712749}], 'Transformers are just complex networks': []}\n",
            "{'neural networks are the best for image recognition': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 199, 'sentence': 'Convolutional neural networks are used for image\\nrecognition and prediction.', 'similarity_score': 0.9343882001078312}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 39, 'sentence': '1.6.5 Convolutional Neural Networks\\nConvolutional neural networks are biologically inspired networks that are used in computer\\nvision for image classiﬁcation and object detection.', 'similarity_score': 0.9264531609446556}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 366, 'sentence': 'The two most popular data sets for testing convolutional neural networks are MNIST\\nandImageNet .', 'similarity_score': 0.9095713538369533}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 52, 'sentence': 'Neural networks are also parameterized models that are learned with continuous optimiza-\\ntion methods.', 'similarity_score': 0.9064293273065994}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 426, 'sentence': 'The hidden states within the\\nneural network can be viewed in a similar way to CPU registers that are used for transitory\\ncomputation, whereas the external memory is used for persistent computation.', 'similarity_score': 0.9016970820213827}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'Deformable part models are convolutional\\nneural networks.', 'similarity_score': 0.8983858231825262}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 281, 'sentence': 'Bidirectional recurrent neural networks are appropriate for applications in which the pre-\\ndictions are not causal based on a historical window.', 'similarity_score': 0.8972948367714159}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 211, 'sentence': 'However, the results of generative\\nadversarial networks are often more realistic because the decoders are explicitly trained to\\ncreate good counterfeits.', 'similarity_score': 0.8968398967818455}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 212, 'sentence': 'Several regularization\\nmethods have also been proposed that are speciﬁcally designed for neural architectures.\\n', 'similarity_score': 0.8968308355195864}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 187, 'sentence': 'One possibility is to predict the test instance using all the neural networks\\nthat were sampled, and then use the geometric mean of the probabilities that are predicted\\nby the diﬀerent networks.', 'similarity_score': 0.8968118360821143}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 64, 'sentence': 'The key point is that with\\ngreater availability of data one can incorporate additional nodes and depth to increase the\\nmodel’s capacity, explaining the superior behavior of neural networks with larger data sets\\n(cf. Figure 2.1).\\n2.3 Neural Architectures for Multiclass Models\\nAll the models discussed so far in this chapter are designed for binary classiﬁcation.', 'similarity_score': 0.8963874265833632}], 'RNN is difficult': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 94, 'sentence': 'This is where eﬃciency is achieved.', 'similarity_score': 0.9110095728722907}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 435, 'sentence': 'This is the', 'similarity_score': 0.8362565495595152}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 170, 'sentence': 'Dropout is\\nanother ensemble technique that is designed for neural networks.', 'similarity_score': 0.8354687407592949}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 114, 'sentence': 'This is why backpropagation is sometimes understood as error propagation.\\n', 'similarity_score': 0.826495813556712}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 182, 'sentence': 'This is the reason that L2-\\nregularization is almost always preferred over L1-regularization is most implementations.\\n', 'similarity_score': 0.8220441939840075}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 186, 'sentence': 'It is\\nnoteworthythatthisapproachmightseemsuperﬁciallysimilarto DropoutandDropConnect ,\\nalthough it is quite diﬀerent.', 'similarity_score': 0.8147961157897934}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 222, 'sentence': 'The main problem with this approach is that it is extremely ineﬃcient.', 'similarity_score': 0.812601525284322}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 197, 'sentence': 'This process is repeated until the complex optimization problem is solved.', 'similarity_score': 0.8104838955955365}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 168, 'sentence': 'It is clear that the linear model is\\nstable,althoughitisunabletoexactlymodelthecurvednatureofthetruedatadistribution.\\n', 'similarity_score': 0.8088913355085388}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 14, 'sentence': 'This is because |y/2−0.5+ˆy|indicates the probability that the\\nprediction is correct.', 'similarity_score': 0.8007653719878096}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 51, 'sentence': 'Regulariza-\\ntion is not used.\\n', 'similarity_score': 0.7976935998398553}], 'Learning Word embeddings': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 43, 'sentence': '1.7.1 Reinforcement Learning\\n', 'similarity_score': 0.7416167008887713}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'Deep Reinforcement Learning with Double Q-\\nLearning.', 'similarity_score': 0.6586812822746783}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 390, 'sentence': '9.5.3 Combining Supervised Learning with Policy Gradients\\nSupervisedlearningisusefulforinitializingtheweightsofthepolicynetworkbeforeapplying\\nreinforcement learning.', 'similarity_score': 0.656674241395668}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'node2vec: Scalable feature learning for networks.', 'similarity_score': 0.6538957611568217}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 52, 'sentence': 'Chapter 2\\nMachine Learning with Shallow Neural\\nNetworks\\n“Simplicity is the ultimate sophistication.”—Leonardo', 'similarity_score': 0.6504808769623618}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 86, 'sentence': 'WORD2VEC: AN APPLICATION OF SIMPLE NEURAL ARCHITECTURES 87\\n2.6 Word2vec: An Application of Simple Neural Archi-\\ntectures\\nNeural network methods have been used to learn word embeddings of text data.', 'similarity_score': 0.6438643682140834}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 197, 'sentence': '2.Curriculum learning:', 'similarity_score': 0.6415818162349093}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 396, 'sentence': '•Reinforcement learning:', 'similarity_score': 0.6415818162349093}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 461, 'sentence': 'NIPS 2016 tutorial: Generative adversarial networks.', 'similarity_score': 0.6401220310180029}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 456, 'sentence': 'Radial Basis Functions: Theory and implementations.', 'similarity_score': 0.6398878282053853}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 312, 'sentence': 'Large Scale Visual Recognition Challenge', 'similarity_score': 0.638335210712749}], 'Transformers are just complex networks': [{'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 464, 'sentence': 'Multilayer feedforward networks are universal\\napproximators.', 'similarity_score': 0.9075661962166607}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 52, 'sentence': 'Neural networks are also parameterized models that are learned with continuous optimiza-\\ntion methods.', 'similarity_score': 0.9040178634178483}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 462, 'sentence': 'Deformable part models are convolutional\\nneural networks.', 'similarity_score': 0.894706689747681}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 170, 'sentence': 'There are several ensemble methods that are speciﬁcally designed for neural net-\\nworks.', 'similarity_score': 0.8910572613515689}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 433, 'sentence': 'Boththegeneratoranddiscriminator\\nare neural networks.', 'similarity_score': 0.8864613524522021}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 79, 'sentence': 'Another issue is that deep networks are harder to train, and\\ntherefore tricks like pretraining are important.', 'similarity_score': 0.8764573251143636}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 36, 'sentence': 'One limiting issue is that these\\nnetworks are not deep, and they typically use only two layers.', 'similarity_score': 0.8671023073878354}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 274, 'sentence': 'These continuous values are eventually converted', 'similarity_score': 0.8659018221101753}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 446, 'sentence': 'Many com-\\npetitive principles are often combined with more traditional feed-forward networks.', 'similarity_score': 0.8646361293656931}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 83, 'sentence': 'Assume that all activation functions are linear.', 'similarity_score': 0.8640516139344231}, {'file': '/content/2018_Book_NeuralNetworksAndDeepLearning.pdf', 'page_no': 216, 'sentence': 'Like feed-forward networks, RBF networks are universal function approximators.\\n', 'similarity_score': 0.8603697600452286}]}\n"
          ]
        }
      ]
    }
  ]
}